# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zyFU15-NfB6ubPOZCuWHvFg5aj6vpZb0
"""

# Importamos las bibliotecas necesarias para cálculos numéricos, aleatorios y visualización
import numpy as np
import random
import matplotlib.pyplot as plt

# Función para generar el laberinto
def generar_laberinto(tamano):
    laberinto = np.ones((tamano, tamano), dtype=int)  # Inicializar con paredes

    # Cambié a un enfoque iterativo para evitar la recursión excesiva
    def abrir_caminos(x, y):
        pila = [(x, y)]
        while pila:
            x, y = pila.pop()
            direcciones = [(0, 2), (0, -2), (2, 0), (-2, 0)]
            random.shuffle(direcciones)
            for dx, dy in direcciones:
                nx, ny = x + dx, y + dy
                if 0 < nx < tamano - 1 and 0 < ny < tamano - 1 and laberinto[nx, ny] == 1:
                    laberinto[nx, ny] = 0
                    laberinto[x + dx // 2, y + dy // 2] = 0
                    pila.append((nx, ny))  # Agregar nueva celda a la pila

    laberinto[1, 1] = 0
    abrir_caminos(1, 1)
    laberinto[tamano - 2, tamano - 2] = 2  # Establecer la meta
    return laberinto

# Acciones y validación de movimientos
acciones = [(0, -1), (0, 1), (-1, 0), (1, 0)]  # Arriba, abajo, izquierda, derecha

def es_movimiento_valido(laberinto, estado, accion):
    x, y = estado
    dx, dy = accion
    nx, ny = x + dx, y + dy
    if 0 <= nx < laberinto.shape[0] and 0 <= ny < laberinto.shape[1]:
        return laberinto[nx, ny] != 1  # No es una pared
    return False

def siguiente_estado(estado, accion):
    x, y = estado
    dx, dy = accion
    return x + dx, y + dy

# Parámetros Q-Learning
alpha = 0.1  # Tasa de aprendizaje
gamma = 0.9  # Factor de descuento
epsilon = 0.1  # Exploración-explotación
episodios = 1000

# Generar el laberinto
tamano = 100
laberinto = generar_laberinto(tamano)

# Inicializar la tabla Q
q_table = np.zeros((tamano, tamano, len(acciones)))

# Función para mostrar el laberinto con la posición actual del agente
def mostrar_laberinto(laberinto, agente=None):
    laberinto_visual = np.copy(laberinto)
    if agente:
        x, y = agente
        laberinto_visual[x, y] = 3  # Usamos 3 para marcar la posición del agente
    plt.imshow(laberinto_visual, cmap="gray")
    plt.show()

# Entrenamiento del agente
for episodio in range(episodios):
    estado = (1, 1)  # Estado inicial
    while True:
        # Elegir acción (exploración o explotación)
        if random.uniform(0, 1) < epsilon:
            accion_idx = random.randint(0, len(acciones) - 1)  # Explorar
        else:
            accion_idx = np.argmax(q_table[estado[0], estado[1]])  # Explotar

        accion = acciones[accion_idx]

        # Validar movimiento
        if not es_movimiento_valido(laberinto, estado, accion):
            continue

        nuevo_estado = siguiente_estado(estado, accion)
        recompensa = 1 if laberinto[nuevo_estado] == 2 else -0.1  # Recompensa

        # Actualizar tabla Q
        mejor_valor_futuro = np.max(q_table[nuevo_estado[0], nuevo_estado[1]])
        q_table[estado[0], estado[1], accion_idx] += alpha * (
            recompensa + gamma * mejor_valor_futuro - q_table[estado[0], estado[1], accion_idx]
        )

        # Mostrar el laberinto con la posición actual del agente
        mostrar_laberinto(laberinto, agente=estado)

        # Mover al nuevo estado
        estado = nuevo_estado

        # Terminar si alcanza la meta
        if laberinto[estado] == 2:
            print(f"Agente alcanzó la meta en episodio {episodio + 1}")
            break

# Resolver el laberinto
def resolver_laberinto(laberinto):
    estado = (1, 1)
    pasos = [estado]
    while laberinto[estado] != 2:
        accion_idx = np.argmax(q_table[estado[0], estado[1]])
        accion = acciones[accion_idx]
        if not es_movimiento_valido(laberinto, estado, accion):
            print("Movimiento inválido, deteniendo.")
            break
        estado = siguiente_estado(estado, accion)
        pasos.append(estado)
    return pasos

# Encontrar la ruta
ruta = resolver_laberinto(laberinto)
print(f"Ruta encontrada: {ruta}")

# Mostrar el laberinto final con la ruta
mostrar_laberinto(laberinto, ruta)